---
title: Adversarial Policies Beat Superhuman Go AIs
venue: International Conference on Machine Learning
names: T. T. Wang, A. Gleave, Nora Belrose, Tom Tseng, Joseph Miller, Kellin Pelrine,
  Michael Dennis, Yawen Duan, V. Pogrebniak, S. Levine, Stuart Russell
tags:
- International Conference on Machine Learning
link: https://arxiv.org/abs/2211.00241
author: Kellin Pelrine
categories: Publications

---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

We attack the state-of-the-art Go-playing AI system KataGo by training adversarial policies against it, achieving a>97% win rate against KataGo running at superhuman settings. Our adversaries do not win by playing Go well. Instead, they trick KataGo into making serious blunders. Our attack transfers zero-shot to other superhuman Go-playing AIs, and is comprehensible to the extent that human experts can implement it without algorithmic assistance to consistently beat superhuman AIs. The core vulnerability uncovered by our attack persists even in KataGo agents adversarially trained to defend against our attack. Our results demonstrate that even superhuman AI systems may harbor surprising failure modes. Example games are available https://goattack.far.ai/.